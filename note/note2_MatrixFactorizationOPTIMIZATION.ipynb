{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/e/673c2598-7ffc-800b-8f89-cf0fe1770989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để giảm tình trạng **OUT OF MEMORY** trong bài toán OTTO với Matrix Factorization, bạn có thể áp dụng các phương pháp tối ưu sau:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Tối ưu hóa dữ liệu đầu vào**\n",
    "#### **a. Chỉ giữ lại sản phẩm phổ biến**\n",
    "- **Lọc top sản phẩm phổ biến nhất**:\n",
    "  - Chỉ giữ lại 1,000-2,000 sản phẩm phổ biến nhất trong tập huấn luyện.\n",
    "  - Ví dụ:\n",
    "    ```python\n",
    "    top_products = interaction_df['product'].value_counts().index[:2000]\n",
    "    interaction_df_filtered = interaction_df[interaction_df['product'].isin(top_products)]\n",
    "    ```\n",
    "- Điều này giảm số cột trong ma trận tương tác.\n",
    "\n",
    "#### **b. Giảm số lượng sessions**\n",
    "- **Lấy tập con nhỏ hơn của sessions**:\n",
    "  - Sử dụng 10,000-20,000 sessions đầu tiên để huấn luyện thử nghiệm trước.\n",
    "  - Ví dụ:\n",
    "    ```python\n",
    "    max_sessions = 20000\n",
    "    interaction_df_filtered = interaction_df[interaction_df['session'].isin(session_ids[:max_sessions])]\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Sử dụng ma trận sparse**\n",
    "- Ma trận tương tác thường rất thưa thớt (sparse), chỉ chứa một số giá trị khác 0. \n",
    "- Sử dụng **`scipy.sparse.csr_matrix`** để tối ưu hóa việc lưu trữ và tính toán.\n",
    "\n",
    "Ví dụ:\n",
    "```python\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "interaction_sparse = csr_matrix(interaction_matrix.values)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Giảm số yếu tố ẩn (`n_components`)**\n",
    "- Giảm số lượng yếu tố ẩn trong SVD:\n",
    "  - Với tập dữ liệu nhỏ hơn, giảm `n_components` xuống còn 10 hoặc 20.\n",
    "- Ví dụ:\n",
    "  ```python\n",
    "  svd = TruncatedSVD(n_components=10, random_state=42)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Sử dụng phân tích theo batch**\n",
    "Nếu dữ liệu quá lớn, chia thành các batch nhỏ hơn để xử lý từng phần:\n",
    "- Huấn luyện SVD trên từng batch của dữ liệu, sau đó kết hợp kết quả.\n",
    "- Sử dụng thư viện hỗ trợ như **Dask** để chia batch và xử lý trên GPU.\n",
    "\n",
    "Ví dụ:\n",
    "```python\n",
    "import dask.array as da\n",
    "from dask_ml.decomposition import TruncatedSVD\n",
    "\n",
    "# Chuyển dữ liệu sang Dask array\n",
    "interaction_dask = da.from_array(interaction_sparse, chunks=(1000, 1000))\n",
    "\n",
    "# Áp dụng SVD trên Dask\n",
    "svd = TruncatedSVD(n_components=10)\n",
    "latent_factors = svd.fit_transform(interaction_dask)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Chọn thuật toán thay thế cho SVD**\n",
    "#### **a. ALS (Alternating Least Squares)**\n",
    "- **ALS** (Alternating Least Squares) là một phương pháp Matrix Factorization hiệu quả hơn cho dữ liệu sparse.\n",
    "- Thư viện: `implicit`.\n",
    "- Ví dụ:\n",
    "  ```python\n",
    "  from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "  model = AlternatingLeastSquares(factors=10, regularization=0.1, iterations=20)\n",
    "  model.fit(interaction_sparse.T)\n",
    "  ```\n",
    "\n",
    "#### **b. NMF (Non-Negative Matrix Factorization)**\n",
    "- Non-Negative Matrix Factorization hoạt động tốt trên dữ liệu sparse và thường yêu cầu ít bộ nhớ hơn.\n",
    "- Thư viện: `sklearn.decomposition.NMF`.\n",
    "- Ví dụ:\n",
    "  ```python\n",
    "  from sklearn.decomposition import NMF\n",
    "\n",
    "  nmf = NMF(n_components=10, init='random', random_state=42)\n",
    "  W = nmf.fit_transform(interaction_sparse)\n",
    "  H = nmf.components_\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Sử dụng GPU với RAPIDS cuDF/cuML**\n",
    "#### **a. Chuyển ma trận sang GPU**\n",
    "- Dùng RAPIDS để xử lý ma trận tương tác trên GPU, giảm thời gian tính toán và bộ nhớ.\n",
    "- Ví dụ:\n",
    "  ```python\n",
    "  import cudf\n",
    "  from cuml.decomposition import TruncatedSVD\n",
    "\n",
    "  # Chuyển DataFrame sang cuDF\n",
    "  interaction_cudf = cudf.DataFrame(interaction_matrix)\n",
    "\n",
    "  # Áp dụng TruncatedSVD với RAPIDS\n",
    "  svd = TruncatedSVD(n_components=10, random_state=42)\n",
    "  latent_factors = svd.fit_transform(interaction_cudf)\n",
    "  ```\n",
    "\n",
    "#### **b. Tối ưu hóa với cuML ALS**\n",
    "- Thư viện RAPIDS cung cấp ALS cho Matrix Factorization trên GPU:\n",
    "  ```python\n",
    "  from cuml.als import ALS\n",
    "\n",
    "  model = ALS(factors=10, regularization=0.1, max_iter=20)\n",
    "  user_factors, item_factors = model.fit(interaction_sparse.T)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Sử dụng kỹ thuật giảm kích thước khác**\n",
    "Nếu SVD không hiệu quả, bạn có thể thử:\n",
    "#### **a. PCA (Principal Component Analysis)**\n",
    "- PCA hoạt động tương tự SVD, nhưng nhanh hơn và tiêu tốn ít bộ nhớ hơn.\n",
    "- Ví dụ:\n",
    "  ```python\n",
    "  from sklearn.decomposition import PCA\n",
    "\n",
    "  pca = PCA(n_components=10)\n",
    "  reduced_matrix = pca.fit_transform(interaction_sparse.toarray())\n",
    "  ```\n",
    "\n",
    "#### **b. T-SNE hoặc UMAP cho trực quan hóa**\n",
    "- Dùng để giảm chiều dữ liệu và trực quan hóa kết quả.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Cấu hình môi trường**\n",
    "#### **a. Sử dụng môi trường High RAM**\n",
    "- Trên Kaggle hoặc Colab, chọn môi trường **High RAM** để tăng bộ nhớ xử lý.\n",
    "#### **b. Tận dụng GPU mạnh hơn**\n",
    "- Sử dụng **NVIDIA P100** hoặc **A100** thay vì T4 để tăng tốc tính toán.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Tóm lại:**\n",
    "- **Bước đầu tiên:** Lọc dữ liệu (sessions và sản phẩm) để giảm kích thước.\n",
    "- **Bước tiếp theo:** Sử dụng ma trận sparse và batch processing.\n",
    "- **Lựa chọn thay thế:** Thử các thuật toán khác như ALS, NMF, hoặc PCA nếu SVD vẫn gây lỗi.\n",
    "- **Cuối cùng:** Chuyển sang GPU với RAPIDS hoặc các môi trường mạnh hơn nếu cần xử lý dữ liệu lớn.\n",
    "\n",
    "Áp dụng các kỹ thuật trên sẽ giảm thiểu lỗi OUT OF MEMORY và tăng hiệu quả của mô hình."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
