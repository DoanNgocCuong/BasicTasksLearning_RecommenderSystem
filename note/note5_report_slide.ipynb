{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary for Presentation Slides\n",
    "\n",
    "Here’s a condensed version of the report for inclusion in slides:\n",
    "\n",
    "---\n",
    "\n",
    "#### **Title Slide**\n",
    "- **Project Title:** Session-Based Recommender System for Retail Products  \n",
    "- **Course:** Web Mining - Fall 2024  \n",
    "- **Instructor:** Ph.D. Nguyen Kiem Hieu  \n",
    "- **Group Members:**  \n",
    "  - Đoàn Ngọc Cường - 20210141  \n",
    "  - Võ Đình Đạt - 20214890  \n",
    "  - Lê Trung Kiên - 20214907  \n",
    "  - Phạm Quang Trung - 20214935  \n",
    "  - Đoàn Thế Vinh - 20210940  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Slide 1: Problem Overview**\n",
    "- **Background:** E-commerce platforms generate vast data on user interactions (clicks, carts, orders).  \n",
    "- **Challenge:** Predicting user actions in anonymous sessions using only session-based data.  \n",
    "- **Relevance:** Improves personalization and sales strategies for retailers.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Slide 2: Dataset Overview**\n",
    "- **Source:** OTTO e-commerce dataset (12M sessions, 220M events).  \n",
    "- **Event Types:**\n",
    "  - Clicks (89.8% of interactions).  \n",
    "  - Add-to-cart (7.8%).  \n",
    "  - Orders (2.4%).  \n",
    "- **Challenges:**\n",
    "  - High sparsity (only 0.0005% possible interactions observed).  \n",
    "  - Large scale: ~1.8M unique products.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Slide 3: Methodology Overview**\n",
    "- **Approach:** Three methods explored.  \n",
    "  1. **Method 1:**  \n",
    "     - Candidate generation (heuristics, Word2Vec, co-visitation).  \n",
    "     - Ranking with LightGBM.  \n",
    "  2. **Method 2:**  \n",
    "     - Collaborative filtering (Item CF, User CF).  \n",
    "     - Ranking with LightGBM and CatBoost.  \n",
    "  3. **Method 3:**  \n",
    "     - Graph Neural Network (GNN) for link prediction on heterogeneous graphs.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Slide 4: Feature Engineering**\n",
    "- **Session Features:** Interaction counts, time-based metrics.  \n",
    "- **Item Features:** Co-occurrence stats, Word2Vec similarity.  \n",
    "- **Contextual Features:** Popularity rank within session clusters.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Slide 5: Evaluation Metrics**\n",
    "- **Metric:** Recall@20 (weighted by click, cart, and order importance).  \n",
    "- **Score Calculation:**  \n",
    "  - \\( \\text{Score} = 0.10 * R_\\text{clicks} + 0.30 * R_\\text{carts} + 0.60 * R_\\text{orders} \\)  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Slide 6: Results**\n",
    "- **Performance Comparison:**  \n",
    "  - Best Recall@20 for clicks, carts, and orders achieved with GNN approach.  \n",
    "  - Classical methods also showed competitive results with optimized feature engineering.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Slide 7: Discussion & Challenges**\n",
    "- **Challenges:**  \n",
    "  - Handling data sparsity and scalability.  \n",
    "  - Balancing diverse interaction types in predictions.  \n",
    "- **Learnings:**  \n",
    "  - Importance of advanced embedding techniques (Word2Vec, GNN).  \n",
    "  - Trade-offs between heuristic methods and deep learning.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Slide 8: Conclusion & Future Work**\n",
    "- **Conclusion:** SBRS effectively predicts session-based actions, enhancing personalization in e-commerce.  \n",
    "- **Future Work:**  \n",
    "  - Incorporate Transformer-based embeddings.  \n",
    "  - Address cold-start problem with auxiliary data.  \n",
    "  - Perform hyperparameter tuning for ranking models.  \n",
    "\n",
    "---\n",
    "\n",
    "This structure provides a clear, engaging, and concise representation of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dưới đây là bảng tóm tắt chi tiết từng phương pháp trong báo cáo:\n",
    "\n",
    "| **Phương pháp**            | **Chi tiết**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | **Ưu điểm**                                                                                                                                                                                                                                                                                                    | **Hạn chế**                                                                                                                                                                                                                                             |\n",
    "|-----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Phương pháp 1**          | **Pipeline:** Retrieve (Candidate Generation) → Re-rank → Top 20<br>- **Candidate Generation:**<br>  + Sử dụng ma trận đồng thăm (co-visitation matrix) để tìm các sản phẩm thường được tương tác cùng nhau.<br>  + Tích hợp Word2Vec để thêm các sản phẩm tương tự theo không gian embedding.<br>  + Tận dụng các mục phổ biến trong cụm session (KMeans clustering).<br>- **Re-rank:** Dùng mô hình LightGBM (LambdaRank) để xếp hạng các sản phẩm dựa trên 100 đặc trưng từ lịch sử tương tác và thông tin ngữ cảnh.                                                                                              | - Đơn giản và dễ triển khai.<br>- Kết hợp nhiều nguồn thông tin để tạo tập ứng viên đa dạng.<br>- LightGBM cho phép tối ưu hóa hiệu suất thông qua tính năng xếp hạng.                                                                                                     | - Phụ thuộc nhiều vào các ma trận đồng thăm và embedding thủ công.<br>- Không linh hoạt nếu có dữ liệu mới hoặc thay đổi mạnh mẽ trong hành vi người dùng.                                                                                             |\n",
    "| **Phương pháp 2**          | **Pipeline:** Tương tự Phương pháp 1<br>- **Candidate Generation:**<br>  + Tận dụng thêm Word2Vec, ma trận đồng thăm (co-visitation matrix), và ma trận phân tích nhân tố (Matrix Factorization).<br>  + Tích hợp các mô hình cộng tác lọc (Collaborative Filtering) dựa trên mục (Item CF) và session (User CF).<br>- **Feature Engineering:**<br>  + Tạo ~200 đặc trưng, bao gồm các thống kê thời gian, mức độ phổ biến và tương tự Word2Vec.<br>- **Re-rank:** Dùng CatBoost Ranker (YetiRank) và LightGBM để tối ưu xếp hạng.                                                                                          | - Tăng độ chính xác nhờ thêm các nguồn dữ liệu như MF và CF.<br>- CatBoost Ranker có khả năng xử lý các vấn đề xếp hạng phức tạp.<br>- Tích hợp nhiều đặc trưng chi tiết.                                                                                              | - Cần thời gian và tài nguyên tính toán cao hơn do sử dụng nhiều kỹ thuật bổ sung.<br>- Dễ bị ảnh hưởng bởi dữ liệu không cân bằng (ví dụ, các sản phẩm ít phổ biến).                                                                                  |\n",
    "| **Phương pháp 3 (GNN)**     | **Cách tiếp cận:**<br>- Biểu diễn bài toán dưới dạng dự đoán liên kết (link prediction) trên đồ thị không đồng nhất (heterogeneous graph).<br>- **Cấu trúc đồ thị:**<br>  + Node: Gồm 2 loại node (session và sản phẩm).<br>  + Edge: Các quan hệ tương tác giữa node (click, cart, order).<br>- **Quy trình:**<br>  + Preprocess: Biến dữ liệu thành node và edge.<br>  + Node Encoder: Biểu diễn node bằng embedding.<br>  + Edge Encoder: Biểu diễn thông tin quan hệ bằng embedding.<br>  + Training: Tối ưu hóa loss bằng Weighted Mean Squared Error (WMSE).                                                                                  | - Hiện đại, phù hợp với dữ liệu phức tạp.<br>- Khả năng biểu diễn tốt các quan hệ không đồng nhất giữa session và sản phẩm.<br>- Mô hình hóa toàn diện hành vi người dùng trong session.<br>- Đa mục tiêu (multi-objective).                                                    | - Yêu cầu tài nguyên tính toán rất lớn.<br>- Cần xử lý đồ thị phức tạp, dễ gặp vấn đề về bộ nhớ trên tập dữ liệu lớn.<br>- Đòi hỏi chuyên môn cao để thiết kế và tối ưu hóa mô hình.                                                                      |\n",
    "\n",
    "### **Tóm tắt:**\n",
    "1. **Phương pháp 1:** Truyền thống, tập trung vào các kỹ thuật thủ công (ma trận đồng thăm, Word2Vec).  \n",
    "2. **Phương pháp 2:** Nâng cao, thêm các kỹ thuật cộng tác lọc và CatBoost để cải thiện hiệu suất.  \n",
    "3. **Phương pháp 3:** Hiện đại, tận dụng GNN để khai thác toàn bộ dữ liệu trong cấu trúc đồ thị phức tạp.  \n",
    "\n",
    "Bạn có thể sử dụng bảng này làm slide tóm tắt nội dung từng phương pháp chi tiết."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# viết TRANSCRIPTION PRESENATION của đoạn METHOD+METRIC NÀY \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. METHOD DETAILS\n",
    "3.1. Method 1\n",
    "The method follows the classical Retrieve (Candidate Generation), Rerank and get the top 20 items for click, add to cart or buy for the session. Approximately 56 candidates are retrieved per session using a combination of session-based heuristics, co-visitation statistics, and Word2Vec embeddings, followed by ranking and selecting the top 20 items for clicks, carts, and orders.\n",
    "3.1.1. Candidate generation\n",
    "The retrieval process incorporates multiple sources to maximize diversity and relevance:\n",
    "Re-visitation matrix: Add all previous items from the session to the pool of candidates.\n",
    "Co-visitation matrix: Add items frequently visited together. Then we add the 20 most frequent items per each previous item. We utilized several interactions between items listed below to create the co-visitation matrix.\n",
    "Click-to-click: items are clicked together in the span of 12 hours.\n",
    "Click-to-cart-or-buy: one item is clicked and then the other is added to cart or ordered in the span of 24 hours.\n",
    "Cart-to-cart: items are added to cart together in 24 hours.\n",
    "Cart-to-buy: one is added to cart and then the other is ordered in 24 hours.\n",
    "Buy-to-buy: items are bought together in a 24-hour interval.\n",
    "Similar item matrix: Add similar items in terms of Word2Vec embeddings.We add at most 20 similar items per each previous item. Embeddings of items are created based on Word2Vec embeddings from the sequence of all items in the session and from sequence of only cart & buy items in the session.\n",
    "Popular items in the same cluster of sessions: Compute sessions embeddings based on Word2Vec embeddings of items in the session (a weighted average by type and time). Find clusters of sessions using KMeans clustering (~50 clusters found). The top 20 most popular items are added from the same cluster.\n",
    "The maximum recall@20 possible for top K retrieved candidates if ranked ideally is shown below.\n",
    "\n",
    "type \n",
    "recall@20-top20\n",
    "recall@20-top100\n",
    "recall@20-top200\n",
    "recall@20-topall\n",
    "clicks\n",
    " 0.196203\n",
    "0.5307\n",
    "0.560093\n",
    "0.569288\n",
    "carts \n",
    " 0.152458\n",
    "0.424199\n",
    "0.467714 \n",
    "0.50739\n",
    "orders \n",
    "0.16003\n",
    "0.481797\n",
    "0.584761\n",
    "0.713684\n",
    "total \n",
    "0.161375\n",
    "0.469408 \n",
    "0.54718\n",
    "0.637356\n",
    "\n",
    "\n",
    "3.1.2. Feature Engineering\n",
    "To enhance ranking, feature engineering is conducted. Approximately 100 features are generated for each candidate, focusing on both interaction history and contextual information. \n",
    "Session specific features:\n",
    "Interaction counts by type (click, cart, order) and their ranks.\n",
    "Time-based features, such as time since the last interaction of a specific type.\n",
    "Relative position and rank of items within the session.\n",
    "Co-occurrence and Similarity Features:\n",
    "Co-occurrence counts and ranks (e.g., frequency of items being clicked or carted together).\n",
    "Word2Vec similarity metrics (Euclidean distance and ranks).\n",
    "Similarity between session embeddings and item embeddings (cosine similarity, Euclidean distance).\n",
    "Popularity Features: Item popularity rank within the same session cluster.\n",
    "3.1.3. Re-ranker Model Training \n",
    "The ranking phase utilized LightGBM with a LambdaRank objective to predict item relevance for clicks, carts, and orders. Separate models were trained for each target type using the following strategy:\n",
    "Target: a retrieved item is marked with 1 if item was clicked, carted, ordered; and 0 if not.\n",
    "Removed sessions without positive samples. This decreased the volume of rows to ~13% of the original dataset for clicks, ~3.5% for carts, and ~2.5% for orders.\n",
    "A maximum of 100 negative samples per session were included, maintaining a positive-to-negative ratio of 1:40.\n",
    "The datasets had the following:\n",
    "\n",
    "Type\n",
    "Avg positive / session\n",
    "Avg negative / session\n",
    "Total rows\n",
    "Sessions\n",
    "Clicks\n",
    "1\n",
    "41\n",
    "40M\n",
    "1M\n",
    "Carts\n",
    "1.3\n",
    "50\n",
    "11M\n",
    "220K\n",
    "Orders\n",
    "1.7\n",
    "57\n",
    "7.5M\n",
    "130K\n",
    "\n",
    "\n",
    "We train 3 LightGBM models for each target with the same parameters as below:\n",
    "PARAMS_LGBM = {\n",
    "  'objective': 'lambdarank',\n",
    "  'boosting_type': 'gbdt',\n",
    "  'metric': 'ndcg',\n",
    "  'n_estimators': 150,\n",
    "  'learning_rate': 0.25,\n",
    "  'max_depth': 4,\n",
    "  'num_leaves': 15,\n",
    "  'colsample_bytree': 0.25,\n",
    "  'subsample': 0.50,\n",
    "  'min_child_samples': 20,\n",
    "  'importance_type': 'gain',\n",
    "  'seed': 42,\n",
    "}\n",
    "\n",
    "No hyperparameter tuning was performed due to time constraints, and parameters were adjusted based on initial experiments.\n",
    "3.2. Method 2\n",
    "The classical pipeline is still applied in this method. The summary of this method can be seen in the image below\n",
    "\n",
    "Figure 3.1: Illustration of the second methods workflow\n",
    "3.2.1. Candidate generation\n",
    "As in the image, the candidates are generated from:\n",
    "Recently interacted items\n",
    "Word2Vec based: A Word2Vec model was trained on item sequences (aids) to learn dense embeddings for each item. These embeddings capture semantic relationships between items based on their co-occurrence patterns. Top-K candidates were retrieved by finding the nearest neighbors in the embedding space, accelerated using FAISS-GPU for efficient similarity search.\n",
    "Co-Visitation Matrix: A co-visitation matrix, inspired by Chris’s methodology, was used to identify candidates based on items frequently appearing together in user sessions. This approach leverages historical interaction data to surface co-related items.\n",
    "Item Matrix Factorization (Item MF): An Item Matrix Factorization model was implemented with item embeddings learned using BPR loss. This encourages items co-occurring in sessions to have similar embeddings. To address biases, the loss was scaled inversely by item popularity (item_size) and temporal difference (ts_diff), ensuring embeddings prioritize temporally proximate co-occurrences while reducing the impact of popular items dominating the representation.\n",
    "User Matrix Factorization (User MF): A User Matrix Factorization model was built, learning session embeddings and item embeddings jointly through BPR loss. This model ensures session-specific preferences are captured effectively. Similar to Item MF, the loss was adjusted inversely by item_size and ts_diff, encouraging embeddings to focus on temporal proximity and mitigate popularity bias.\n",
    "Item-Based Collaborative Filtering (Item CF): Item-based collaborative filtering was implemented using Polars to compute similarity weights between item pairs. Candidate items were generated based on the most similar items, determined by aggregating weights using sum, min, max, or mean. Adjustments to weights included scaling inversely by item_size, inversely by ts_diff, and multiplying by a trend coefficient that emphasizes more recent interactions.\n",
    "User-Based Collaborative Filtering (User CF): User-based collaborative filtering was similarly implemented, focusing on session-level interactions to identify candidates. Adjustments similar to Item CF were applied to mitigate biases and emphasize temporal relevance.\n",
    "3.2.2. Feature Engineering\n",
    "We created approximately 200 features to capture diverse session, item, and interaction-level characteristics. \n",
    "Session-Level Features:\n",
    "Features were aggregated over sessions to capture temporal and behavioral patterns, including:\n",
    "Timestamp Statistics: Aggregated metrics such as mean, min, max, and standard deviation of interaction timestamps.\n",
    "Interaction Frequency: Count and rank of candidate selection events within sessions.\n",
    "Item-Level Features:\n",
    "Features describing individual item interactions and properties, such as:\n",
    "Candidate Characteristics: Metrics like candidate score, rank, and whether the item was selected.\n",
    "Interaction Time Distribution: Mean hour of interactions (e.g., clicks, carts, orders) aggregated over items.\n",
    "Interaction Statistics:\n",
    "Aggregated counts of interaction types (e.g., clicks, carts, orders) over various time windows.\n",
    "Multi-action probabilities for each aid, capturing the likelihood of specific actions .\n",
    "Temporal Dynamics:\n",
    "Temporal features ensured the model could account for recency effects and patterns over different periods.\n",
    "3.2.3. Ranker training\n",
    "For the rankers, we experimented with 3 models\n",
    "LightGBM Ranker (LambdaRank):\n",
    "This model was used to directly optimize a ranking objective. LambdaRank adapts gradient boosting for ranking tasks by incorporating pairwise comparisons and position-based weighting, making it well-suited for improving metrics like NDCG and Recall.\n",
    "CatBoost Classifier (Logloss):\n",
    "A classification approach was applied using CatBoost, optimizing for log-loss. This model predicts the likelihood of an item being interacted with based on the feature set. The predictions were then used to rank items by their probabilities.\n",
    "CatBoost Ranker (YetiRank):\n",
    "The YetiRank algorithm in CatBoost was used for direct ranking optimization. YetiRank incorporates pairwise and listwise ranking methods, considering user preferences and engagement levels to produce highly relevant rankings.\n",
    "\n",
    "3.3. Method 3\n",
    "Another way of approaching the session based recommendation system problem beside the classical architecture is using Graph Neural Network, that is we formulate the problem into a link prediction problem. Heterogeneous graph (also called a heterogeneous information network) is a type of graph where nodes belong to different types and edges represent different relationships. This is particularly useful for our problem as sessions (or users) can click, add to cart or order an item that can be of many types (different aid).  The objective is to build a multi-objective link prediction on a large-scale e-commerce heterogeneous graph. An illustration of this method is shown below.\n",
    "\n",
    "Figure 3.2: An illustration of the heterogeneous graph (left) which consists of multiple node and edge types and multi-objective recommendations (right) which takes prediction on multiple event types and items.\n",
    "\n",
    "\n",
    "First, we will preprocess the data into nodes and edges. For the nodes, we will have 2 types of nodes: the first represents the users (sessions) and the other represents the items. The latter will also encapsulate its embeddings (randomly initialized) along with its id. We connect these 2 nodes with the ‘event’ edge. The edges will contain their source and destination id along with its label (click, cart or order). The edges are undirected. We build a model that contains a node encoder and edge encoder and train it with weighted mean squared error. The overall workflow can be seen below:\n",
    "\n",
    "Figure 3.3: An illustration of the overall workflow of the third method.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4. EVALUATION METRICS\n",
    "For the evaluation metrics, we will use Recall@20 provided by the competition on each action type. The three recall values are weight-averaged:\n",
    "score = 0.10 * Rclicks+0.30 * Rcarts + 0.60 * Rorders\n",
    "where R is defined as\n",
    "Rtype=iN | {predicted aids}i, type  {ground truth aids}i,type |iN min(20, | {ground truth aids}i, type |)\n",
    "and N is the total number of sessions in the test set, and predicted aids are the predictions for each session-type (e.g., each row in the submission file) truncated after the first 20 predictions.\n",
    "For each session in the test data, the task is to predict the aid values for each type that occur after the last timestamp is the test session. In other words, the test data contains sessions truncated by timestamp, and weare to predict what occurs after the point of truncation.\n",
    "For clicks there is only a single ground truth value for each session, which is the next aid clicked during the session. The ground truth for carts and orders contains all aid values that were added to a cart and ordered respectively during the session.\n",
    "\n",
    "\n",
    "--------\n",
    "viết TRANSCRIPTION PRESENATION của đoạn METHOD+METRIC NÀY "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Phương pháp chi tiết: Giải thích dễ hiểu**\n",
    "\n",
    "#### **3.1. Phương pháp 1: Pipeline truyền thống**\n",
    "Phương pháp này sử dụng 3 bước chính: \n",
    "1. **Tạo danh sách ứng viên (Candidate Generation)**: Chọn ra khoảng 100 sản phẩm tiềm năng cho mỗi phiên giao dịch.\n",
    "2. **Trích xuất đặc trưng (Feature Engineering)**: Tạo khoảng 200 đặc trưng từ dữ liệu.\n",
    "3. **Xếp hạng (Ranking)**: Xếp hạng các sản phẩm ứng viên và chọn ra 20 sản phẩm tốt nhất.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3.1.1. Tạo danh sách ứng viên**\n",
    "- **Ma trận đồng xuất hiện (Co-visitation Matrix)**: Xác định các sản phẩm thường xuyên được tương tác cùng nhau. Ví dụ:  \n",
    "  - **Click-to-click**: Hai sản phẩm được nhấp chuột trong vòng 12 giờ.  \n",
    "  - **Click-to-cart-or-buy**: Một sản phẩm được nhấp, sau đó sản phẩm khác được thêm vào giỏ hàng hoặc mua trong 24 giờ.  \n",
    "  - **Cart-to-buy**: Một sản phẩm được thêm vào giỏ hàng, sau đó sản phẩm khác được mua trong 24 giờ.  \n",
    "\n",
    "- **Ma trận đồng xuất hiện có trọng số (Weighted Co-visitation Matrix)**: Thêm các trọng số để ưu tiên các tương tác gần đây hơn hoặc các hành động quan trọng hơn (ví dụ: mua hàng quan trọng hơn nhấp chuột).  \n",
    "\n",
    "=> Kết quả: Tạo danh sách khoảng 100 ứng viên cho mỗi phiên giao dịch.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3.1.2. Trích xuất đặc trưng (Feature Engineering)**\n",
    "- **Đặc trưng ma trận đồng xuất hiện**: Dùng dữ liệu từ ma trận đồng xuất hiện để tạo các trọng số và đặc trưng.  \n",
    "- **Đặc trưng nhúng (Embedding Features)**:  \n",
    "  - **Word2Vec**: Mô hình Word2Vec được huấn luyện trên mã sản phẩm để tạo đặc trưng nhúng.  \n",
    "  - **Matrix Factorization**: Phân rã ma trận để tạo ra các đặc trưng tương tự Word2Vec.  \n",
    "- **Đặc trưng cấp độ phiên (Session-Level Features)**: Ví dụ: Thời gian tương tác trung bình, số lần nhấp chuột trong phiên.  \n",
    "- **Đặc trưng cấp độ sản phẩm (Item-Level Features)**: Ví dụ: Độ phổ biến của sản phẩm, thời gian sản phẩm được tương tác nhiều nhất.  \n",
    "- **Đặc trưng động theo thời gian (Temporal Features)**: Phân tích tần suất và thời gian tương tác gần đây.  \n",
    "\n",
    "=> Kết quả: Tạo được một tập hợp đặc trưng đa dạng để cải thiện độ chính xác của mô hình.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3.1.3. Xếp hạng (Ranking)**\n",
    "- **Gán nhãn**:  \n",
    "  - **1**: Nếu sản phẩm được nhấp chuột, thêm giỏ hàng, hoặc mua.  \n",
    "  - **0**: Nếu không có hành động nào xảy ra.  \n",
    "- **Huấn luyện mô hình**: Sử dụng XGBoost để xếp hạng các ứng viên theo xác suất xảy ra hành động.  \n",
    "- **Bộ dữ liệu**:  \n",
    "  - Giữ lại ~13% dữ liệu cho nhấp chuột, ~3.5% cho thêm giỏ hàng, và ~2.5% cho mua hàng (do dữ liệu mất cân bằng).  \n",
    "\n",
    "---\n",
    "\n",
    "#### **3.1.4. Dự đoán**\n",
    "- **Quy trình dự đoán**:  \n",
    "  - Tạo danh sách ứng viên từ dữ liệu kiểm tra.  \n",
    "  - Dùng mô hình đã huấn luyện để xếp hạng các sản phẩm cho từng hành động: nhấp chuột, thêm giỏ hàng, mua hàng.  \n",
    "  - Tạo danh sách 20 sản phẩm gợi ý cuối cùng, ưu tiên những sản phẩm có khả năng cao nhất.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3.2. Phương pháp 2: Mạng đồ thị (Graph Neural Network - GNN)**\n",
    "- **Ý tưởng chính**:  \n",
    "  - Biểu diễn dữ liệu dưới dạng đồ thị không đồng nhất (**heterogeneous graph**).  \n",
    "  - Các nút gồm:\n",
    "    - **Phiên giao dịch (Session)**: Tương ứng với người dùng.  \n",
    "    - **Sản phẩm (Item)**: Tương ứng với mã sản phẩm (article ID).  \n",
    "  - Các cạnh (edges): Đại diện cho các hành động (nhấp chuột, thêm giỏ hàng, mua hàng).  \n",
    "\n",
    "- **Mục tiêu**:  \n",
    "  - Dự đoán liên kết (link prediction) giữa nút \"phiên giao dịch\" và nút \"sản phẩm\" dựa trên hành động.\n",
    "\n",
    "- **Quy trình**:  \n",
    "  1. **Tiền xử lý**: Chuyển dữ liệu thành đồ thị với nút và cạnh tương ứng.  \n",
    "  2. **Huấn luyện**:  \n",
    "     - Dùng bộ mã hóa nút (**node encoder**) và cạnh (**edge encoder**).  \n",
    "     - Tối ưu với hàm lỗi bình phương có trọng số (**weighted mean squared error**).  \n",
    "\n",
    "=> Kết quả: Mạng đồ thị giúp mô hình hóa các mối quan hệ phức tạp giữa người dùng và sản phẩm trong phiên giao dịch.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Kết luận**\n",
    "Hai phương pháp (Pipeline truyền thống và GNN) đều có những ưu điểm riêng:  \n",
    "- **Pipeline truyền thống**: Hiệu quả, dễ triển khai.  \n",
    "- **GNN**: Xử lý tốt dữ liệu thưa và quan hệ phức tạp.  \n",
    "Cả hai phương pháp đều mang lại giải pháp gợi ý hiệu quả cho bài toán hệ thống gợi ý dựa trên phiên giao dịch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parquet is a columnar storage file format that is specifically optimized for big data and analytical workloads. It is widely used in systems like Apache Spark, Apache Hive, and Hadoop due to its efficiency in both storage and processing.\n",
    "\n",
    "### Key Features of Parquet\n",
    "1. **Columnar Storage**:\n",
    "   - Data is stored column by column instead of row by row. This makes it faster to access specific columns, which is particularly useful for analytical queries that often need only a subset of columns.\n",
    "\n",
    "2. **Efficient Compression**:\n",
    "   - Parquet applies compression techniques at the column level. Since data in a column is usually of the same type, it achieves higher compression ratios compared to row-based formats like CSV or JSON.\n",
    "\n",
    "3. **Schema Support**:\n",
    "   - Parquet includes metadata about the structure of the data, making it self-describing. This allows tools to understand the data's schema without additional configuration.\n",
    "\n",
    "4. **Improved Performance**:\n",
    "   - Because it reads only the necessary columns, Parquet reduces I/O operations and speeds up data processing tasks.\n",
    "\n",
    "5. **Compatibility**:\n",
    "   - It is supported by most big data processing frameworks, including Apache Spark, Pandas, and Presto, making it versatile and widely used.\n",
    "\n",
    "### Benefits of Using Parquet\n",
    "- **Faster Query Performance**: Columnar storage aligns with the access patterns of analytical queries.\n",
    "- **Smaller Storage Footprint**: Efficient compression reduces disk space usage.\n",
    "- **Scalability**: It can handle large datasets efficiently without consuming excessive memory or computational resources.\n",
    "\n",
    "### Use Case in Your Script\n",
    "In your context, converting JSONL to Parquet involves:\n",
    "- Breaking down events into a structured tabular format.\n",
    "- Mapping event types to integers and converting timestamps to seconds for better performance.\n",
    "- Storing the processed data in Parquet format to facilitate faster loading and querying.\n",
    "\n",
    "This transformation is ideal for optimizing performance when dealing with large-scale data analytics."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
